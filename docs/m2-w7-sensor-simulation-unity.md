# Module 2: The Digital Twin (Gazebo & Unity)

## Week 7: Sensor Simulation (LIDAR, Depth Cameras, IMUs) with Unity Visualization

### 1. Advanced Sensor Simulation in Digital Twins

Digital twins mein advanced sensor simulation real-world robot deployment se pehle perception algorithms ko test aur validate karne ke liye buhat zaroori hai. Accurate sensor models mein noise, distortions, aur environmental factors (e.g., light conditions, material properties) shamil hote hain taake simulated data real-world data ke qareeb ho. Yeh sim-to-real gap ko kam karne mein madad karta hai.

### 2. LIDAR and Depth Camera Simulation

LIDAR aur depth cameras autonomous navigation aur object perception ke liye critical sensors hain. Simulation environments in sensors ke data streams ko generate karte hain, jo real-time mein robot ke perception stack ko feed kiye ja sakte hain.

**Technical Content:**
- **LIDAR Simulation**: Ray casting, point cloud generation, adjustable parameters (e.g., number of beams, angular resolution, range, noise models).
- **Depth Camera Simulation**: Depth map generation from 3D scene, RGB-D data output, sensor specific noise (e.g., IR speckle, depth uncertainty).
- `gazebo_ros_pkgs` mein sensor plugins (e.g., `libgazebo_ros_ray_sensor.so` for LIDAR, `libgazebo_ros_camera.so` for RGB-D).

**Code Example (XML - Gazebo LIDAR Sensor Plugin Snippet):**
```xml
<gazebo reference="lidar_link">
  <sensor type="ray" name="lidar_sensor">
    <pose>0 0 0 0 0 0</pose>
    <visualize>true</visualize>
    <update_rate>10</update_rate>
    <ray>
      <scan>
        <horizontal>
          <samples>360</samples>
          <resolution>1</resolution>
          <min_angle>-3.14159</min_angle>
          <max_angle>3.14159</max_angle>
        </horizontal>
        <vertical>
          <samples>1</samples> <!-- 2D LIDAR -->
          <resolution>1</resolution>
          <min_angle>0</min_angle>
          <max_angle>0</max_angle>
        </vertical>
      </scan>
      <range>
        <min>0.1</min>
        <max>10.0</max>
        <resolution>0.01</resolution>
      </range>
      <noise>
        <type>gaussian</type>
        <mean>0.0</mean>
        <stddev>0.01</stddev>
      </noise>
    </ray>
    <plugin name="gazebo_ros_lidar_controller" filename="libgazebo_ros_ray_sensor.so">
      <ros> <!-- ROS 2 specific configuration -->
        <namespace>/</namespace>
        <argument>~/out</argument>
        <remap>~/out:=scan</remap>
      </ros>
      <output_type>sensor_msgs/LaserScan</output_type>
      <frame_name>lidar_link</frame_name>
    </plugin>
  </sensor>
</gazebo>
```

**Visual Aid Placeholder:**
```
[Image/Diagram: A simulated robot in Gazebo with LIDAR rays visualizing the scan. Another image showing a depth map generated by a simulated depth camera.]
```

### 3. IMU (Inertial Measurement Unit) Simulation

IMU simulation robot ki motion, orientation, aur acceleration ko estimate karne ke liye essential hai. Simulated IMUs linear acceleration, angular velocity, aur orientation (agar magnetometer shamil ho) data provide karte hain, jismein noise aur bias models bhi shamil hote hain taake real-world sensors ki characteristics ko emulate kiya ja sake.

**Technical Content:**
- Accelerometer, gyroscope, aur magnetometer models.
- Noise models: Gaussian noise, bias, random walk.
- IMU data integration aur orientation estimation (e.g., complementary filter, Kalman filter) simulated data ke saath.
- `libgazebo_ros_imu_sensor.so` plugin ka istemal.

**Code Example (XML - Gazebo IMU Sensor Plugin Snippet):**
```xml
<gazebo reference="imu_link">
  <sensor type="imu" name="imu_sensor">
    <always_on>true</always_on>
    <update_rate>100</update_rate>
    <imu>
      <orientation>
        <x>0</x>
        <y>0</y>
        <z>0</z>
        <w>1</w>
      </orientation>
      <angular_velocity>
        <x>0</x>
        <y>0</y>
        <z>0</z>
      </angular_velocity>
      <linear_acceleration>
        <x>0</x>
        <y>0</y>
        <z>0</z>
      </linear_acceleration>
      <noise>
        <type>gaussian</type>
        <mean>0.0</mean>
        <stddev>0.0002</stddev>
        <bias_mean>0.0000075</bias_mean>
        <bias_stddev>0.0000008</bias_stddev>
      </noise>
    </imu>
    <plugin name="gazebo_ros_imu_controller" filename="libgazebo_ros_imu_sensor.so">
      <ros> <!-- ROS 2 specific configuration -->
        <namespace>/</namespace>
        <argument>~/out</argument>
        <remap>~/out:=imu</remap>
      </ros>
      <initial_orientation_as_reference>false</initial_orientation_as_reference>
      <frame_name>imu_link</frame_name>
    </plugin>
  </sensor>
</gazebo>
```

**Visual Aid Placeholder:**
```
[Image/Diagram: A graph showing simulated IMU data (accelerations, angular velocities) with noise compared to ground truth.]
```

### 4. Unity for High-Fidelity Visualization and Simulation

Jab Gazebo physics simulation ke liye behtar hai, Unity game engine high-fidelity visualization, rich environmental design, aur advanced sensor simulation features provide karta hai, khas kar ke photorealistic rendering aur custom sensor models ke liye. Unity ka istemal NVIDIA Isaac Sim jaise platforms mein bhi hota hai.

**Technical Content:**
- Unity Robotics Hub: ROS 2 integration, packages (e.g., `ROS-TCP-Connector`, `Unity-Robotics-Visualizations`).
- High-quality asset creation aur import.
- Custom sensor scripts (e.g., C# scripts for raycasting LIDAR, depth camera rendering).
- Render pipelines (URP, HDRP) for photorealism.

**Code Example (Conceptual - C# Unity Script for a Simple Raycast LIDAR):**
```csharp
using UnityEngine;
using System.Collections.Generic;

public class SimpleUnityLidar : MonoBehaviour
{
    public int numRays = 360;
    public float maxRange = 10f;
    public float scanAngle = 360f;
    public float updateRate = 10f; // Hz

    private float timeSinceLastScan = 0f;
    private float angleIncrement;
    private List<float> ranges = new List<float>();

    void Start()
    {
        angleIncrement = scanAngle / numRays;
    }

    void Update()
    {
        timeSinceLastScan += Time.deltaTime;
        if (timeSinceLastScan >= (1f / updateRate))
        {
            PerformScan();
            timeSinceLastScan = 0f;
        }
    }

    void PerformScan()
    {
        ranges.Clear();
        for (int i = 0; i < numRays; i++)
        {
            float currentAngle = (i * angleIncrement) - (scanAngle / 2f);
            Quaternion rotation = Quaternion.AngleAxis(currentAngle, transform.up);
            Vector3 direction = rotation * transform.forward;

            RaycastHit hit;
            if (Physics.Raycast(transform.position, direction, out hit, maxRange))
            {
                ranges.Add(hit.distance);
                Debug.DrawRay(transform.position, direction * hit.distance, Color.red, 1f/updateRate);
            }
            else
            {
                ranges.Add(maxRange);
                Debug.DrawRay(transform.position, direction * maxRange, Color.green, 1f/updateRate);
            }
        }
        Debug.Log("LIDAR scan performed. Number of ranges: " + ranges.Count);
        // In a real application, this data would be published to ROS 2
    }

    // You could add a method here to get the current scan data
    public List<float> GetCurrentScanData()
    {
        return ranges;
    }
}
```

**Visual Aid Placeholder:**
```
[Image/Diagram: A robot model in a highly detailed Unity environment, with simulated sensor data (e.g., LIDAR rays, camera view frustum) overlayed.]
```

**Hardware Context:**
- **RTX GPU**: Unity mein high-fidelity simulations aur photorealistic rendering ke liye RTX GPUs zaroori hain. Yeh especially synthetic data generation aur visualization ke liye useful hai jo deep learning models ko train karne ke liye use hoti hai.
- **Jetson Orin Nano**: Unity visualization aur simulation tools generally Jetson Orin Nano par direct run nahi karte kyunki unhe desktop-class GPUs ki zaroorat hoti hai. Lekin, Jetson device par chalne wale ROS 2 nodes Unity mein simulate kiye gaye robots se data receive kar sakte hain aur commands bhej sakte hain, is tarah ek hybrid simulation setup banaya ja sakta hai.